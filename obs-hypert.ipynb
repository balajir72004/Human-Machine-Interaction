{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-15T15:30:13.503760Z",
     "iopub.status.busy": "2025-04-15T15:30:13.503349Z",
     "iopub.status.idle": "2025-04-15T15:30:16.199274Z",
     "shell.execute_reply": "2025-04-15T15:30:16.198394Z",
     "shell.execute_reply.started": "2025-04-15T15:30:13.503716Z"
    }
   },
   "outputs": [],
   "source": [
    "# Obesity Risk Prediction using Ensemble Learning\n",
    "# Author: ChatGPT (based on Mahasarabesh's request)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier, ExtraTreesClassifier, VotingClassifier, GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "import xgboost as xgb\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Load dataset\n",
    "col_names = [\"Gender\", \"Age\", \"Height\", \"Weight\", \"family_history_with_overweight\", \"FAVC\", \"FCVC\", \"NCP\", \"CAEC\", \"SMOKE\", \"CH2O\", \"SCC\", \"FAF\", \"TUE\", \"CALC\", \"MTRANS\", \"NObeyesdad\"]\n",
    "data = pd.read_csv(\"/kaggle/input/obesity-data-set/ObesityDataSet_raw_and_data_sinthetic.csv\", names=col_names, header=0)\n",
    "\n",
    "# Label Encoding\n",
    "encoder = LabelEncoder()\n",
    "for col in ['Gender', 'family_history_with_overweight', 'FAVC', 'CAEC', 'SMOKE', 'SCC', 'CALC', 'MTRANS', 'NObeyesdad']:\n",
    "    if col in data.columns:\n",
    "        data[col] = encoder.fit_transform(data[col].astype(str))\n",
    "\n",
    "# Outlier handling (Age and NCP)\n",
    "def remove_outliers_iqr(df, col):\n",
    "    Q1 = df[col].quantile(0.25)\n",
    "    Q3 = df[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    median_val = df[col].median()\n",
    "    df[col] = np.where((df[col] < lower_bound) | (df[col] > upper_bound), median_val, df[col])\n",
    "    return df\n",
    "\n",
    "for col in ['Age', 'NCP']:\n",
    "    if col in data.columns:\n",
    "        data = remove_outliers_iqr(data, col)\n",
    "\n",
    "# Feature Scaling\n",
    "target = 'NObeyesdad'\n",
    "features = data.columns.tolist()\n",
    "features.remove(target)\n",
    "scaler = MinMaxScaler()\n",
    "data[features] = scaler.fit_transform(data[features])\n",
    "\n",
    "# Split data\n",
    "X = data[features]\n",
    "y = data[target]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "# Hyperparameter grids\n",
    "param_grids = {\n",
    "    'XGB': {\n",
    "        'learning_rate': [0.01, 0.05, 0.1],\n",
    "        'max_depth': [3, 5, 7],\n",
    "        'n_estimators': [500, 1000],\n",
    "        'min_child_weight': [1, 5, 10],\n",
    "        'gamma': [0, 0.5, 1],\n",
    "        'subsample': [0.6, 0.8, 1.0],\n",
    "        'colsample_bytree': [0.6, 0.8, 1.0]\n",
    "    },\n",
    "    'GB': {\n",
    "        'learning_rate': [0.01, 0.05, 0.1],\n",
    "        'n_estimators': [500, 1000],\n",
    "        'max_depth': [3, 4, 5]\n",
    "    },\n",
    "    'CB': {\n",
    "        'learning_rate': [0.01, 0.05, 0.1],\n",
    "        'n_estimators': [500, 1000],\n",
    "        'depth': [2, 4, 6],\n",
    "        'min_data_in_leaf': [50, 100, 200]\n",
    "    },\n",
    "    'BDT': {\n",
    "        'n_estimators': [100, 300, 500],\n",
    "        'bootstrap_features': [True, False]\n",
    "    },\n",
    "    'RF': {\n",
    "        'n_estimators': [500, 1000],\n",
    "        'max_features': ['sqrt', 'log2', None],\n",
    "        'max_depth': [None, 10, 20]\n",
    "    },\n",
    "    'ET': {\n",
    "        'n_estimators': [500, 1000],\n",
    "        'max_depth': [None, 50, 100],\n",
    "        'min_samples_split': [2, 5, 10]\n",
    "    },\n",
    "    'VC': {\n",
    "        # No parameters to tune directly in VotingClassifier unless tuning base models\n",
    "    }\n",
    "}\n",
    "\n",
    "# Base models\n",
    "base_models = {\n",
    "    'XGB': xgb.XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', random_state=42),\n",
    "    'GB': GradientBoostingClassifier(random_state=45),\n",
    "    'CB': CatBoostClassifier(verbose=0, thread_count=-1, random_state=45),\n",
    "    'BDT': BaggingClassifier(base_estimator=DecisionTreeClassifier(), random_state=42, n_jobs=-1),\n",
    "    'RF': RandomForestClassifier(random_state=42),\n",
    "    'ET': ExtraTreesClassifier(random_state=42),\n",
    "    'VC': VotingClassifier(estimators=[\n",
    "        ('lr', LogisticRegression(max_iter=1000, random_state=42)),\n",
    "        ('dt', DecisionTreeClassifier(random_state=42)),\n",
    "        ('svm', SVC(probability=True, random_state=42))\n",
    "    ], voting='soft')\n",
    "}\n",
    "\n",
    "# Tune models\n",
    "tuned_models = {}\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-15T15:30:19.724653Z",
     "iopub.status.busy": "2025-04-15T15:30:19.724105Z",
     "iopub.status.idle": "2025-04-15T17:28:39.922481Z",
     "shell.execute_reply": "2025-04-15T17:28:39.921511Z",
     "shell.execute_reply.started": "2025-04-15T15:30:19.724625Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tuning XGB...\n",
      "Best Params for XGB: {'colsample_bytree': 0.8, 'gamma': 0, 'learning_rate': 0.05, 'max_depth': 5, 'min_child_weight': 1, 'n_estimators': 1000, 'subsample': 0.8}\n",
      "\n",
      "Tuning GB...\n",
      "Best Params for GB: {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 500}\n",
      "\n",
      "Tuning CB...\n",
      "Best Params for CB: {'depth': 6, 'learning_rate': 0.1, 'min_data_in_leaf': 50, 'n_estimators': 1000}\n",
      "\n",
      "Tuning BDT...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params for BDT: {'bootstrap_features': True, 'n_estimators': 500}\n",
      "\n",
      "Tuning RF...\n",
      "Best Params for RF: {'max_depth': None, 'max_features': None, 'n_estimators': 1000}\n",
      "\n",
      "Tuning ET...\n",
      "Best Params for ET: {'max_depth': None, 'min_samples_split': 2, 'n_estimators': 500}\n",
      "\n",
      "Tuning VC...\n",
      "\n",
      "XGB Evaluation:\n",
      "Accuracy: 96.22%\n",
      "Precision: 96.52%\n",
      "Recall: 96.22%\n",
      "F1-Score: 96.26%\n",
      "Confusion Matrix:\n",
      " [[49  5  0  0  0  0  0]\n",
      " [ 1 57  0  0  0  0  0]\n",
      " [ 0  0 68  0  0  0  2]\n",
      " [ 0  0  1 59  0  0  0]\n",
      " [ 0  0  0  1 64  0  0]\n",
      " [ 0  5  0  0  0 53  0]\n",
      " [ 0  0  1  0  0  0 57]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.91      0.94        54\n",
      "           1       0.85      0.98      0.91        58\n",
      "           2       0.97      0.97      0.97        70\n",
      "           3       0.98      0.98      0.98        60\n",
      "           4       1.00      0.98      0.99        65\n",
      "           5       1.00      0.91      0.95        58\n",
      "           6       0.97      0.98      0.97        58\n",
      "\n",
      "    accuracy                           0.96       423\n",
      "   macro avg       0.96      0.96      0.96       423\n",
      "weighted avg       0.97      0.96      0.96       423\n",
      "\n",
      "\n",
      "GB Evaluation:\n",
      "Accuracy: 95.74%\n",
      "Precision: 95.96%\n",
      "Recall: 95.74%\n",
      "F1-Score: 95.76%\n",
      "Confusion Matrix:\n",
      " [[48  6  0  0  0  0  0]\n",
      " [ 1 57  0  0  0  0  0]\n",
      " [ 0  0 66  1  0  2  1]\n",
      " [ 0  0  2 58  0  0  0]\n",
      " [ 0  0  0  0 65  0  0]\n",
      " [ 0  3  0  0  0 54  1]\n",
      " [ 0  0  0  1  0  0 57]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.89      0.93        54\n",
      "           1       0.86      0.98      0.92        58\n",
      "           2       0.97      0.94      0.96        70\n",
      "           3       0.97      0.97      0.97        60\n",
      "           4       1.00      1.00      1.00        65\n",
      "           5       0.96      0.93      0.95        58\n",
      "           6       0.97      0.98      0.97        58\n",
      "\n",
      "    accuracy                           0.96       423\n",
      "   macro avg       0.96      0.96      0.96       423\n",
      "weighted avg       0.96      0.96      0.96       423\n",
      "\n",
      "\n",
      "CB Evaluation:\n",
      "Accuracy: 96.45%\n",
      "Precision: 96.61%\n",
      "Recall: 96.45%\n",
      "F1-Score: 96.48%\n",
      "Confusion Matrix:\n",
      " [[52  2  0  0  0  0  0]\n",
      " [ 0 56  0  0  0  2  0]\n",
      " [ 0  0 69  0  0  0  1]\n",
      " [ 0  0  1 59  0  0  0]\n",
      " [ 0  0  1  0 64  0  0]\n",
      " [ 0  6  0  0  0 52  0]\n",
      " [ 0  0  1  0  0  1 56]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.96      0.98        54\n",
      "           1       0.88      0.97      0.92        58\n",
      "           2       0.96      0.99      0.97        70\n",
      "           3       1.00      0.98      0.99        60\n",
      "           4       1.00      0.98      0.99        65\n",
      "           5       0.95      0.90      0.92        58\n",
      "           6       0.98      0.97      0.97        58\n",
      "\n",
      "    accuracy                           0.96       423\n",
      "   macro avg       0.97      0.96      0.96       423\n",
      "weighted avg       0.97      0.96      0.96       423\n",
      "\n",
      "\n",
      "BDT Evaluation:\n",
      "Accuracy: 96.93%\n",
      "Precision: 97.28%\n",
      "Recall: 96.93%\n",
      "F1-Score: 96.95%\n",
      "Confusion Matrix:\n",
      " [[50  4  0  0  0  0  0]\n",
      " [ 0 58  0  0  0  0  0]\n",
      " [ 0  0 70  0  0  0  0]\n",
      " [ 0  0  1 59  0  0  0]\n",
      " [ 0  0  0  1 64  0  0]\n",
      " [ 0  6  0  0  0 51  1]\n",
      " [ 0  0  0  0  0  0 58]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.93      0.96        54\n",
      "           1       0.85      1.00      0.92        58\n",
      "           2       0.99      1.00      0.99        70\n",
      "           3       0.98      0.98      0.98        60\n",
      "           4       1.00      0.98      0.99        65\n",
      "           5       1.00      0.88      0.94        58\n",
      "           6       0.98      1.00      0.99        58\n",
      "\n",
      "    accuracy                           0.97       423\n",
      "   macro avg       0.97      0.97      0.97       423\n",
      "weighted avg       0.97      0.97      0.97       423\n",
      "\n",
      "\n",
      "RF Evaluation:\n",
      "Accuracy: 93.85%\n",
      "Precision: 94.19%\n",
      "Recall: 93.85%\n",
      "F1-Score: 93.91%\n",
      "Confusion Matrix:\n",
      " [[48  6  0  0  0  0  0]\n",
      " [ 1 54  0  0  0  3  0]\n",
      " [ 0  0 68  0  0  1  1]\n",
      " [ 0  0  2 58  0  0  0]\n",
      " [ 0  0  1  0 64  0  0]\n",
      " [ 0  4  0  0  0 53  1]\n",
      " [ 0  0  6  0  0  0 52]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.89      0.93        54\n",
      "           1       0.84      0.93      0.89        58\n",
      "           2       0.88      0.97      0.93        70\n",
      "           3       1.00      0.97      0.98        60\n",
      "           4       1.00      0.98      0.99        65\n",
      "           5       0.93      0.91      0.92        58\n",
      "           6       0.96      0.90      0.93        58\n",
      "\n",
      "    accuracy                           0.94       423\n",
      "   macro avg       0.94      0.94      0.94       423\n",
      "weighted avg       0.94      0.94      0.94       423\n",
      "\n",
      "\n",
      "ET Evaluation:\n",
      "Accuracy: 93.85%\n",
      "Precision: 94.02%\n",
      "Recall: 93.85%\n",
      "F1-Score: 93.89%\n",
      "Confusion Matrix:\n",
      " [[51  3  0  0  0  0  0]\n",
      " [ 0 53  0  0  0  5  0]\n",
      " [ 0  0 68  0  0  0  2]\n",
      " [ 0  0  1 59  0  0  0]\n",
      " [ 0  0  0  1 64  0  0]\n",
      " [ 0  6  1  0  0 50  1]\n",
      " [ 0  1  3  0  0  2 52]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.94      0.97        54\n",
      "           1       0.84      0.91      0.88        58\n",
      "           2       0.93      0.97      0.95        70\n",
      "           3       0.98      0.98      0.98        60\n",
      "           4       1.00      0.98      0.99        65\n",
      "           5       0.88      0.86      0.87        58\n",
      "           6       0.95      0.90      0.92        58\n",
      "\n",
      "    accuracy                           0.94       423\n",
      "   macro avg       0.94      0.94      0.94       423\n",
      "weighted avg       0.94      0.94      0.94       423\n",
      "\n",
      "\n",
      "VC Evaluation:\n",
      "Accuracy: 89.83%\n",
      "Precision: 90.00%\n",
      "Recall: 89.83%\n",
      "F1-Score: 89.89%\n",
      "Confusion Matrix:\n",
      " [[47  7  0  0  0  0  0]\n",
      " [ 3 48  0  0  0  6  1]\n",
      " [ 0  0 63  1  0  0  6]\n",
      " [ 0  0  1 59  0  0  0]\n",
      " [ 0  0  0  1 64  0  0]\n",
      " [ 0  6  0  0  0 49  3]\n",
      " [ 1  1  5  0  0  1 50]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.87      0.90        54\n",
      "           1       0.77      0.83      0.80        58\n",
      "           2       0.91      0.90      0.91        70\n",
      "           3       0.97      0.98      0.98        60\n",
      "           4       1.00      0.98      0.99        65\n",
      "           5       0.88      0.84      0.86        58\n",
      "           6       0.83      0.86      0.85        58\n",
      "\n",
      "    accuracy                           0.90       423\n",
      "   macro avg       0.90      0.90      0.90       423\n",
      "weighted avg       0.90      0.90      0.90       423\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for name in base_models:\n",
    "    print(f\"\\nTuning {name}...\")\n",
    "    if name == 'VC':\n",
    "        tuned_models[name] = base_models[name]\n",
    "    else:\n",
    "        grid = GridSearchCV(base_models[name], param_grids[name], scoring='accuracy', cv=kfold, n_jobs=-1)\n",
    "        grid.fit(X_train, y_train)\n",
    "        print(f\"Best Params for {name}:\", grid.best_params_)\n",
    "        tuned_models[name] = grid.best_estimator_\n",
    "\n",
    "# Evaluate tuned models\n",
    "for name, model in tuned_models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    rec = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    print(f\"\\n{name} Evaluation:\")\n",
    "    print(f\"Accuracy: {acc*100:.2f}%\")\n",
    "    print(f\"Precision: {prec*100:.2f}%\")\n",
    "    print(f\"Recall: {rec*100:.2f}%\")\n",
    "    print(f\"F1-Score: {f1*100:.2f}%\")\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "    print(\"Classification Report:\\n\", classification_report(y_test, y_pred, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 3401032,
     "sourceId": 5922459,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31012,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
