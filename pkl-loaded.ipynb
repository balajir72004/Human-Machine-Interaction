{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71986934-aeba-4841-a207-ee945ce96709",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obesity Risk Prediction using Ensemble Learning\n",
    "# Author: ChatGPT (based on Mahasarabesh's request)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier, ExtraTreesClassifier, VotingClassifier, GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "import xgboost as xgb\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Load dataset\n",
    "col_names = [\"Gender\", \"Age\", \"Height\", \"Weight\", \"family_history_with_overweight\", \"FAVC\", \"FCVC\", \"NCP\", \"CAEC\", \"SMOKE\", \"CH2O\", \"SCC\", \"FAF\", \"TUE\", \"CALC\", \"MTRANS\", \"NObeyesdad\"]\n",
    "data = pd.read_csv(\"ObesityDataSet.csv\", names=col_names, header=0)\n",
    "\n",
    "# Label Encoding\n",
    "encoder = LabelEncoder()\n",
    "for col in ['Gender', 'family_history_with_overweight', 'FAVC', 'CAEC', 'SMOKE', 'SCC', 'CALC', 'MTRANS', 'NObeyesdad']:\n",
    "    if col in data.columns:\n",
    "        data[col] = encoder.fit_transform(data[col].astype(str))\n",
    "\n",
    "# Outlier handling (Age and NCP)\n",
    "def remove_outliers_iqr(df, col):\n",
    "    Q1 = df[col].quantile(0.25)\n",
    "    Q3 = df[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    median_val = df[col].median()\n",
    "    df[col] = np.where((df[col] < lower_bound) | (df[col] > upper_bound), median_val, df[col])\n",
    "    return df\n",
    "\n",
    "for col in ['Age', 'NCP']:\n",
    "    if col in data.columns:\n",
    "        data = remove_outliers_iqr(data, col)\n",
    "\n",
    "# Feature Scaling\n",
    "target = 'NObeyesdad'\n",
    "features = data.columns.tolist()\n",
    "features.remove(target)\n",
    "scaler = MinMaxScaler()\n",
    "data[features] = scaler.fit_transform(data[features])\n",
    "\n",
    "# Split data\n",
    "X = data[features]\n",
    "y = data[target]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "# Hyperparameter grids\n",
    "param_grids = {\n",
    "    'XGB': {\n",
    "        'learning_rate': [0.01, 0.05, 0.1],\n",
    "        'max_depth': [3, 5, 7],\n",
    "        'n_estimators': [500, 1000],\n",
    "        'min_child_weight': [1, 5, 10],\n",
    "        'gamma': [0, 0.5, 1],\n",
    "        'subsample': [0.6, 0.8, 1.0],\n",
    "        'colsample_bytree': [0.6, 0.8, 1.0]\n",
    "    },\n",
    "    'GB': {\n",
    "        'learning_rate': [0.01, 0.05, 0.1],\n",
    "        'n_estimators': [500, 1000],\n",
    "        'max_depth': [3, 4, 5]\n",
    "    },\n",
    "    'CB': {\n",
    "        'learning_rate': [0.01, 0.05, 0.1],\n",
    "        'n_estimators': [500, 1000],\n",
    "        'depth': [2, 4, 6],\n",
    "        'min_data_in_leaf': [50, 100, 200]\n",
    "    },\n",
    "    'BDT': {\n",
    "        'n_estimators': [100, 300, 500],\n",
    "        'bootstrap_features': [True, False]\n",
    "    },\n",
    "    'RF': {\n",
    "        'n_estimators': [500, 1000],\n",
    "        'max_features': ['sqrt', 'log2', None],\n",
    "        'max_depth': [None, 10, 20]\n",
    "    },\n",
    "    'ET': {\n",
    "        'n_estimators': [500, 1000],\n",
    "        'max_depth': [None, 50, 100],\n",
    "        'min_samples_split': [2, 5, 10]\n",
    "    },\n",
    "    'VC': {\n",
    "        # No parameters to tune directly in VotingClassifier unless tuning base models\n",
    "    }\n",
    "}\n",
    "\n",
    "# Base models\n",
    "base_models = {\n",
    "    'XGB': xgb.XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', random_state=42,colsample_bytree= 0.8, gamma= 0, learning_rate= 0.05, max_depth= 5, min_child_weight= 1, n_estimators= 1000, subsample= 0.8),\n",
    "    'GB': GradientBoostingClassifier(random_state=45,learning_rate= 0.1, max_depth= 5, n_estimators= 500),\n",
    "    'CB': CatBoostClassifier(verbose=0, thread_count=-1, random_state=45,depth= 6, learning_rate= 0.1, min_data_in_leaf= 50, n_estimators= 1000),\n",
    "    'BDT': BaggingClassifier(estimator=DecisionTreeClassifier(), random_state=42, n_jobs=-1,bootstrap_features= True, n_estimators= 500),\n",
    "    'RF': RandomForestClassifier(random_state=42,max_depth= None, max_features= None, n_estimators= 1000),\n",
    "    'ET': ExtraTreesClassifier(random_state=42,max_depth= None, min_samples_split= 2, n_estimators= 500),\n",
    "    'VC': VotingClassifier(estimators=[\n",
    "        ('lr', LogisticRegression(max_iter=1000, random_state=42)),\n",
    "        ('dt', DecisionTreeClassifier(random_state=42)),\n",
    "        ('svm', SVC(probability=True, random_state=42))\n",
    "    ], voting='soft')\n",
    "}\n",
    "\n",
    "# Tune models\n",
    "tuned_models = {}\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f90b6022-6f96-4520-8f32-e7d66c37df1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "XGB Evaluation:\n",
      "Accuracy: 96.22%\n",
      "Precision: 96.53%\n",
      "Recall: 96.22%\n",
      "F1-Score: 96.25%\n",
      "Confusion Matrix:\n",
      " [[49  5  0  0  0  0  0]\n",
      " [ 1 57  0  0  0  0  0]\n",
      " [ 0  0 69  0  0  0  1]\n",
      " [ 0  0  1 59  0  0  0]\n",
      " [ 0  0  0  1 64  0  0]\n",
      " [ 0  5  0  0  0 52  1]\n",
      " [ 0  0  0  1  0  0 57]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.91      0.94        54\n",
      "           1       0.85      0.98      0.91        58\n",
      "           2       0.99      0.99      0.99        70\n",
      "           3       0.97      0.98      0.98        60\n",
      "           4       1.00      0.98      0.99        65\n",
      "           5       1.00      0.90      0.95        58\n",
      "           6       0.97      0.98      0.97        58\n",
      "\n",
      "    accuracy                           0.96       423\n",
      "   macro avg       0.96      0.96      0.96       423\n",
      "weighted avg       0.97      0.96      0.96       423\n",
      "\n",
      "\n",
      "GB Evaluation:\n",
      "Accuracy: 95.74%\n",
      "Precision: 95.96%\n",
      "Recall: 95.74%\n",
      "F1-Score: 95.76%\n",
      "Confusion Matrix:\n",
      " [[48  6  0  0  0  0  0]\n",
      " [ 1 57  0  0  0  0  0]\n",
      " [ 0  0 66  1  0  2  1]\n",
      " [ 0  0  2 58  0  0  0]\n",
      " [ 0  0  0  0 65  0  0]\n",
      " [ 0  3  0  0  0 54  1]\n",
      " [ 0  0  0  1  0  0 57]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.89      0.93        54\n",
      "           1       0.86      0.98      0.92        58\n",
      "           2       0.97      0.94      0.96        70\n",
      "           3       0.97      0.97      0.97        60\n",
      "           4       1.00      1.00      1.00        65\n",
      "           5       0.96      0.93      0.95        58\n",
      "           6       0.97      0.98      0.97        58\n",
      "\n",
      "    accuracy                           0.96       423\n",
      "   macro avg       0.96      0.96      0.96       423\n",
      "weighted avg       0.96      0.96      0.96       423\n",
      "\n",
      "\n",
      "CB Evaluation:\n",
      "Accuracy: 96.45%\n",
      "Precision: 96.61%\n",
      "Recall: 96.45%\n",
      "F1-Score: 96.48%\n",
      "Confusion Matrix:\n",
      " [[52  2  0  0  0  0  0]\n",
      " [ 0 56  0  0  0  2  0]\n",
      " [ 0  0 69  0  0  0  1]\n",
      " [ 0  0  1 59  0  0  0]\n",
      " [ 0  0  1  0 64  0  0]\n",
      " [ 0  6  0  0  0 52  0]\n",
      " [ 0  0  1  0  0  1 56]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.96      0.98        54\n",
      "           1       0.88      0.97      0.92        58\n",
      "           2       0.96      0.99      0.97        70\n",
      "           3       1.00      0.98      0.99        60\n",
      "           4       1.00      0.98      0.99        65\n",
      "           5       0.95      0.90      0.92        58\n",
      "           6       0.98      0.97      0.97        58\n",
      "\n",
      "    accuracy                           0.96       423\n",
      "   macro avg       0.97      0.96      0.96       423\n",
      "weighted avg       0.97      0.96      0.96       423\n",
      "\n",
      "\n",
      "BDT Evaluation:\n",
      "Accuracy: 96.93%\n",
      "Precision: 97.28%\n",
      "Recall: 96.93%\n",
      "F1-Score: 96.95%\n",
      "Confusion Matrix:\n",
      " [[50  4  0  0  0  0  0]\n",
      " [ 0 58  0  0  0  0  0]\n",
      " [ 0  0 70  0  0  0  0]\n",
      " [ 0  0  1 59  0  0  0]\n",
      " [ 0  0  0  1 64  0  0]\n",
      " [ 0  6  0  0  0 51  1]\n",
      " [ 0  0  0  0  0  0 58]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.93      0.96        54\n",
      "           1       0.85      1.00      0.92        58\n",
      "           2       0.99      1.00      0.99        70\n",
      "           3       0.98      0.98      0.98        60\n",
      "           4       1.00      0.98      0.99        65\n",
      "           5       1.00      0.88      0.94        58\n",
      "           6       0.98      1.00      0.99        58\n",
      "\n",
      "    accuracy                           0.97       423\n",
      "   macro avg       0.97      0.97      0.97       423\n",
      "weighted avg       0.97      0.97      0.97       423\n",
      "\n",
      "\n",
      "RF Evaluation:\n",
      "Accuracy: 93.85%\n",
      "Precision: 94.19%\n",
      "Recall: 93.85%\n",
      "F1-Score: 93.91%\n",
      "Confusion Matrix:\n",
      " [[48  6  0  0  0  0  0]\n",
      " [ 1 54  0  0  0  3  0]\n",
      " [ 0  0 68  0  0  1  1]\n",
      " [ 0  0  2 58  0  0  0]\n",
      " [ 0  0  1  0 64  0  0]\n",
      " [ 0  4  0  0  0 53  1]\n",
      " [ 0  0  6  0  0  0 52]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.89      0.93        54\n",
      "           1       0.84      0.93      0.89        58\n",
      "           2       0.88      0.97      0.93        70\n",
      "           3       1.00      0.97      0.98        60\n",
      "           4       1.00      0.98      0.99        65\n",
      "           5       0.93      0.91      0.92        58\n",
      "           6       0.96      0.90      0.93        58\n",
      "\n",
      "    accuracy                           0.94       423\n",
      "   macro avg       0.94      0.94      0.94       423\n",
      "weighted avg       0.94      0.94      0.94       423\n",
      "\n",
      "\n",
      "ET Evaluation:\n",
      "Accuracy: 93.85%\n",
      "Precision: 94.02%\n",
      "Recall: 93.85%\n",
      "F1-Score: 93.89%\n",
      "Confusion Matrix:\n",
      " [[51  3  0  0  0  0  0]\n",
      " [ 0 53  0  0  0  5  0]\n",
      " [ 0  0 68  0  0  0  2]\n",
      " [ 0  0  1 59  0  0  0]\n",
      " [ 0  0  0  1 64  0  0]\n",
      " [ 0  6  1  0  0 50  1]\n",
      " [ 0  1  3  0  0  2 52]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.94      0.97        54\n",
      "           1       0.84      0.91      0.88        58\n",
      "           2       0.93      0.97      0.95        70\n",
      "           3       0.98      0.98      0.98        60\n",
      "           4       1.00      0.98      0.99        65\n",
      "           5       0.88      0.86      0.87        58\n",
      "           6       0.95      0.90      0.92        58\n",
      "\n",
      "    accuracy                           0.94       423\n",
      "   macro avg       0.94      0.94      0.94       423\n",
      "weighted avg       0.94      0.94      0.94       423\n",
      "\n",
      "\n",
      "VC Evaluation:\n",
      "Accuracy: 89.83%\n",
      "Precision: 90.00%\n",
      "Recall: 89.83%\n",
      "F1-Score: 89.89%\n",
      "Confusion Matrix:\n",
      " [[47  7  0  0  0  0  0]\n",
      " [ 3 48  0  0  0  6  1]\n",
      " [ 0  0 63  1  0  0  6]\n",
      " [ 0  0  1 59  0  0  0]\n",
      " [ 0  0  0  1 64  0  0]\n",
      " [ 0  6  0  0  0 49  3]\n",
      " [ 1  1  5  0  0  1 50]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.87      0.90        54\n",
      "           1       0.77      0.83      0.80        58\n",
      "           2       0.91      0.90      0.91        70\n",
      "           3       0.97      0.98      0.98        60\n",
      "           4       1.00      0.98      0.99        65\n",
      "           5       0.88      0.84      0.86        58\n",
      "           6       0.83      0.86      0.85        58\n",
      "\n",
      "    accuracy                           0.90       423\n",
      "   macro avg       0.90      0.90      0.90       423\n",
      "weighted avg       0.90      0.90      0.90       423\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate tuned models\n",
    "for name, model in base_models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    rec = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    print(f\"\\n{name} Evaluation:\")\n",
    "    print(f\"Accuracy: {acc*100:.2f}%\")\n",
    "    print(f\"Precision: {prec*100:.2f}%\")\n",
    "    print(f\"Recall: {rec*100:.2f}%\")\n",
    "    print(f\"F1-Score: {f1*100:.2f}%\")\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "    print(\"Classification Report:\\n\", classification_report(y_test, y_pred, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6cfeaa51-bbab-4686-a958-b352279d29dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 'XGB' saved at H:\\mini_project6\\XGB.pkl\n",
      "Model 'GB' saved at H:\\mini_project6\\GB.pkl\n",
      "Model 'CB' saved at H:\\mini_project6\\CB.pkl\n",
      "Model 'BDT' saved at H:\\mini_project6\\BDT.pkl\n",
      "Model 'RF' saved at H:\\mini_project6\\RF.pkl\n",
      "Model 'ET' saved at H:\\mini_project6\\ET.pkl\n",
      "Model 'VC' saved at H:\\mini_project6\\VC.pkl\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Directory path where you want to save the models\n",
    "save_dir = 'H:\\mini_project6'\n",
    "\n",
    "# Ensure the directory exists\n",
    "import os\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "\n",
    "# Save each model to a separate pickle file\n",
    "for model_name, model in base_models.items():\n",
    "    file_path = os.path.join(save_dir, f\"{model_name}.pkl\")\n",
    "    with open(file_path, 'wb') as file:\n",
    "        pickle.dump(model, file)\n",
    "    print(f\"Model '{model_name}' saved at {file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9dc53069-203c-42f5-935c-34bc8f71db7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 'XGB' loaded successfully.\n",
      "Model 'GB' loaded successfully.\n",
      "Model 'CB' loaded successfully.\n",
      "Model 'BDT' loaded successfully.\n",
      "Model 'RF' loaded successfully.\n",
      "Model 'ET' loaded successfully.\n",
      "Model 'VC' loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Model names\n",
    "# Dictionary to store loaded models\n",
    "loaded_models = {}\n",
    "models=['XGB','GB','CB','BDT','RF','ET','VC']\n",
    "# Load each model\n",
    "for model_name in models:\n",
    "    file_path = f'H:\\\\mini_project\\\\{model_name}.pkl'\n",
    "    with open(file_path, 'rb') as file:\n",
    "        loaded_models[model_name] = pickle.load(file)\n",
    "    print(f\"Model '{model_name}' loaded successfully.\")\n",
    "\n",
    "# Now, you can access each model through the 'loaded_models' dictionary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1ddbb50c-dcbe-4e56-8671-d9f32334c9b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: [0 1 6 4 3 2 3 1 2 1 0 1 4 5 1 5 2 2 6 1 1 3 3 5 6 5 2 4 6 2 3 2 5 5 3 1 3\n",
      " 0 4 0 5 0 4 4 6 4 0 6 3 1 4 0 5 2 6 1 4 4 4 3 6 6 0 6 5 2 2 0 3 2 4 5 0 0\n",
      " 2 0 0 0 2 2 1 6 4 2 1 1 3 5 6 6 3 6 2 3 5 6 0 1 4 3 2 3 3 5 6 4 2 2 6 3 6\n",
      " 1 4 3 4 4 0 4 1 1 4 6 4 0 2 3 6 6 5 3 4 6 0 0 0 5 2 2 3 0 4 2 3 2 2 3 6 2\n",
      " 0 5 5 5 4 0 3 3 4 2 5 6 1 3 2 2 4 6 5 6 6 3 5 1 1 3 3 5 2 5 1 6 2 3 2 3 0\n",
      " 0 1 4 2 5 5 5 4 5 1 3 6 1 3 2 3 4 6 6 1 0 2 5 1 3 0 4 1 6 6 6 5 2 2 6 1 4\n",
      " 2 2 1 5 3 4 3 5 6 0 2 4 6 6 1 0 3 5 4 1 4 2 1 5 1 0 2 3 6 1 4 6 3 4 2 4 6\n",
      " 3 4 2 1 2 4 2 6 4 1 2 2 0 4 5 6 4 3 0 2 4 2 4 6 1 1 1 2 6 2 4 5 1 0 1 2 0\n",
      " 5 5 6 1 6 5 1 0 1 6 2 5 4 4 4 1 4 2 6 4 1 4 2 5 0 4 1 2 6 3 5 3 0 4 6 4 2\n",
      " 1 2 0 1 5 6 3 3 5 1 3 0 1 1 0 3 3 4 3 1 3 1 1 4 0 4 2 1 3 0 6 2 0 4 5 5 1\n",
      " 0 6 3 4 3 2 2 0 1 2 3 1 0 2 0 5 5 1 5 2 4 5 4 6 1 0 6 3 6 1 0 3 4 0 4 2 5\n",
      " 1 5 2 2 6 1 1 1 3 2 1 3 6 3 1 2]\n",
      "Accuracy: 96.93%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.93      0.96        54\n",
      "           1       0.85      1.00      0.92        58\n",
      "           2       0.99      1.00      0.99        70\n",
      "           3       0.98      0.98      0.98        60\n",
      "           4       1.00      0.98      0.99        65\n",
      "           5       1.00      0.88      0.94        58\n",
      "           6       0.98      1.00      0.99        58\n",
      "\n",
      "    accuracy                           0.97       423\n",
      "   macro avg       0.97      0.97      0.97       423\n",
      "weighted avg       0.97      0.97      0.97       423\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Example: Make predictions with the XGBoost model\n",
    "xgb_model = loaded_models['BDT']\n",
    "\n",
    "# Assuming you have preprocessed test data X_test\n",
    "y_pred = xgb_model.predict(X_test)\n",
    "\n",
    "# Print the predictions\n",
    "print(\"Predictions:\", y_pred)\n",
    "\n",
    "# Evaluate the model\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Classification Report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e313265-cd23-44a8-83e8-5fefca50a738",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 3401032,
     "sourceId": 5922459,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31012,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
